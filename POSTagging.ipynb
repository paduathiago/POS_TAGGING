{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging - Thiago Pádua - 2020007066\n",
    "A tarefa de Part-of-Speech Tagging (POS) consiste em rotular palavras de um texto de acordo com a sua classe gramatical, como substantivo, verbo, adjetivo. Esse processo é fundamental para diversas aplicações em Processamento de Linguagem Natural (PLN), pois permite uma compreensão mais detalhada da estrutura sintática e semântica das sentenças.\n",
    "\n",
    "Por exemplo, considere a seguinte frase:\n",
    "\"A raposa azul dorme tranquilamente.\"\n",
    "\n",
    "    \"A\" pode receber a tag de artigo definido.\n",
    "    \"raposa\" pode receber a tag de substantivo.\n",
    "    \"azul\" pode receber a tag de adjetivo.\n",
    "    \"dorme\" pode receber a tag de verbo.\n",
    "    \"tranquilamente\" pode receber a tag de advérbio.\n",
    "\n",
    "Neste trabalho, o objetivo é explorar a tarefa de POS Tagging para a língua portuguesa, utilizando o corpus Mac-Morpho. Além disso, será implementado um modelo capaz de classificar palavras com precisão, analisando como o contexto influencia a atribuição de classes gramaticais. Por fim, investigaremos os desafios e as limitações do processo, discutindo as classes que apresentam maior e menor precisão ao longo do experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"macmorpho-v3/macmorpho-test.txt\"\n",
    "train_file_path = \"macmorpho-v3/macmorpho-train.txt\"\n",
    "dev_file_path = \"macmorpho-v3/macmorpho-dev.txt\"\n",
    "\n",
    "def load_text_data(file_path):\n",
    "    \"\"\"\n",
    "    :param file_path: path to the .txt file containing the data\n",
    "    :return: List of sentences, where each sentence is a list of tuples (word, tag)\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:  # Ignore empty lines\n",
    "                # Generate a list of tuples (word, tag)\n",
    "                word_tags = [tuple(word.split('_')) for word in line.split()]\n",
    "                sentences.append(word_tags)\n",
    "    return sentences\n",
    "\n",
    "test_data = load_text_data(test_file_path)\n",
    "train_data = load_text_data(train_file_path)\n",
    "dev_data = load_text_data(dev_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: [('Salto', 'N'), ('sete', 'ADJ')]\n",
      "Sentence 2: [('O', 'ART'), ('grande', 'ADJ'), ('assunto', 'N'), ('da', 'PREP+ART'), ('semana', 'N'), ('em', 'PREP'), ('Nova', 'NPROP'), ('York', 'NPROP'), ('é', 'V'), ('a', 'ART'), ('edição', 'N'), ('da', 'PREP+ART'), ('revista', 'N'), ('\"', 'PU'), ('New', 'NPROP'), ('Yorker', 'NPROP'), ('\"', 'PU'), ('que', 'PRO-KS'), ('está', 'V'), ('nas', 'PREP+ART'), ('bancas', 'N'), ('.', 'PU')]\n",
      "Sentence 3: [('Número', 'N'), ('duplo', 'ADJ'), ('especial', 'ADJ'), (',', 'PU'), ('é', 'V'), ('inteirinho', 'ADJ'), ('dedicado', 'PCP'), ('a', 'PREP'), ('ensaios', 'N'), ('sobre', 'PREP'), ('moda', 'N'), ('.', 'PU')]\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(test_data[:3]):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago/UFMG/9_periodo/NLP/TP2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lisaterumi/postagger-portuguese\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"lisaterumi/postagger-portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "teste = \"A cidade mais linda de Minas Gerais é Belo Horizonte\".split(sep=' ')\n",
    "\n",
    "test_words = [t[0] for t in teste]\n",
    "inputs = tokenizer(teste, return_tensors=\"pt\", is_split_into_words=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens gerados: ['[CLS]', 'A', 'cidade', 'mais', 'lin', '##da', 'de', 'Minas', 'Gerais', 'é', 'Belo', 'Horizonte', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens gerados:\", tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: [CLS], Palavra Original: None\n",
      "Token: A, Palavra Original: A\n",
      "Token: cidade, Palavra Original: cidade\n",
      "Token: mais, Palavra Original: mais\n",
      "Token: lin, Palavra Original: linda\n",
      "Token: ##da, Palavra Original: linda\n",
      "Token: de, Palavra Original: de\n",
      "Token: Minas, Palavra Original: Minas\n",
      "Token: Gerais, Palavra Original: Gerais\n",
      "Token: é, Palavra Original: é\n",
      "Token: Belo, Palavra Original: Belo\n",
      "Token: Horizonte, Palavra Original: Horizonte\n",
      "Token: [SEP], Palavra Original: None\n"
     ]
    }
   ],
   "source": [
    "# Obter os índices das palavras originais correspondentes a cada token\n",
    "word_ids = inputs.word_ids(batch_index=0)  # Adicione o batch_index para evitar erros de dimensão\n",
    "\n",
    "# Exibir os mapeamentos\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "# Mostrar os tokens e as palavras originais\n",
    "for token, word_id in zip(tokens, word_ids):\n",
    "    palavra_original = teste[word_id] if word_id is not None else None\n",
    "    print(f\"Token: {token}, Palavra Original: {palavra_original}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, None]\n",
      "Tags preditas para palavras: [('A', 'ART'), ('cidade', 'N'), ('mais', 'ADV'), ('linda', 'ADJ'), ('de', 'PREP'), ('Minas', 'NPROP'), ('Gerais', 'NPROP'), ('é', 'V'), ('Belo', 'NPROP'), ('Horizonte', 'NPROP')]\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Mapear previsões para palavras originais\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "word_ids = inputs.word_ids(batch_index=0)\n",
    "\n",
    "\n",
    "tags = []\n",
    "current_word = None\n",
    "for token, word_id, pred in zip(tokens, word_ids, predictions[0].tolist()):\n",
    "    if word_id is None:  # Ignore special tokens\n",
    "        continue\n",
    "\n",
    "    # Associate tag only with the first token of each word. Repeated ids will be ignored\n",
    "    if word_id != current_word:\n",
    "        tags.append(model.config.id2label[pred])\n",
    "        current_word = word_id\n",
    "\n",
    "print(\"Tags preditas para palavras:\", list(zip(teste, tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras originais: ['A', 'c', 'm', 'l', 'd', 'M', 'G', 'é', 'B', 'H']\n",
      "Tags preditas: ['ART', 'N', 'ADV', 'ADJ', 'ADJ', 'PREP', 'NPROP', 'NPROP', 'V', 'NPROP', 'NPROP']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Mapear previsões para palavras originais\n",
    "tags = [model.config.id2label[pred] for pred, word_id in zip(predictions[0].tolist(), word_ids) if word_id is not None]\n",
    "\n",
    "print(\"Palavras originais:\", test_words)\n",
    "print(\"Tags preditas:\", tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags filtradas: ['N', 'ADV', 'ADJ', 'ADJ', 'PREP', 'NPROP', 'NPROP', 'V', 'NPROP', 'NPROP']\n"
     ]
    }
   ],
   "source": [
    "filtered_tags = [tag for tag, word_id in zip(tags, word_ids) if word_id is not None]\n",
    "\n",
    "print(\"Tags filtradas:\", filtered_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "predicted_token_class_ids = torch.argmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = model.config.id2label\n",
    "predicted_labels = [label_map[label_id.item()] for label_id in predicted_token_class_ids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "pos_tags = list(zip(tokens, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: <pad>\n",
      "A: ART\n",
      "cidade: N\n",
      "mais: ADV\n",
      "lin: ADJ\n",
      "##da: ADJ\n",
      "de: PREP\n",
      "Minas: NPROP\n",
      "Gerais: NPROP\n",
      "é: V\n",
      "Belo: NPROP\n",
      "Horizonte: NPROP\n",
      "[SEP]: <pad>\n"
     ]
    }
   ],
   "source": [
    "for token, tag in pos_tags:\n",
    "    print(f\"{token}: {tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
