{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging - Thiago Pádua - 2020007066\n",
    "A tarefa de Part-of-Speech Tagging (POS) consiste em rotular palavras de um texto de acordo com a sua classe gramatical, como substantivo, verbo, adjetivo. Esse processo é fundamental para diversas aplicações em Processamento de Linguagem Natural (PLN), pois permite uma compreensão mais detalhada da estrutura sintática e semântica das sentenças.\n",
    "\n",
    "Por exemplo, considere a seguinte frase:\n",
    "\"A raposa azul dorme tranquilamente.\"\n",
    "\n",
    "    \"A\" pode receber a tag de artigo definido.\n",
    "    \"raposa\" pode receber a tag de substantivo.\n",
    "    \"azul\" pode receber a tag de adjetivo.\n",
    "    \"dorme\" pode receber a tag de verbo.\n",
    "    \"tranquilamente\" pode receber a tag de advérbio.\n",
    "\n",
    "Neste trabalho, o objetivo é explorar a tarefa de POS Tagging para a língua portuguesa, utilizando o corpus Mac-Morpho. Além disso, será implementado um modelo capaz de classificar palavras com precisão, analisando como o contexto influencia a atribuição de classes gramaticais. Por fim, investigaremos os desafios e as limitações do processo, discutindo as classes que apresentam maior e menor precisão ao longo do experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_data(file_path):\n",
    "    \"\"\"\n",
    "    :param file_path: path to the .txt file containing the data\n",
    "    :return: List of sentences, where each sentence is a list of tuples (word, tag)\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:  # Ignore empty lines\n",
    "                # Generate a list of tuples (word, tag)\n",
    "                word_tags = [tuple(word.split('_')) for word in line.split()]\n",
    "                sentences.append(word_tags)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"macmorpho-v3/macmorpho-test.txt\"\n",
    "train_file_path = \"macmorpho-v3/macmorpho-train.txt\"\n",
    "dev_file_path = \"macmorpho-v3/macmorpho-dev.txt\"\n",
    "\n",
    "test_data = load_text_data(test_file_path)\n",
    "train_data = load_text_data(train_file_path)\n",
    "dev_data = load_text_data(dev_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: [('Salto', 'N'), ('sete', 'ADJ')]\n",
      "Sentence 2: [('O', 'ART'), ('grande', 'ADJ'), ('assunto', 'N'), ('da', 'PREP+ART'), ('semana', 'N'), ('em', 'PREP'), ('Nova', 'NPROP'), ('York', 'NPROP'), ('é', 'V'), ('a', 'ART'), ('edição', 'N'), ('da', 'PREP+ART'), ('revista', 'N'), ('\"', 'PU'), ('New', 'NPROP'), ('Yorker', 'NPROP'), ('\"', 'PU'), ('que', 'PRO-KS'), ('está', 'V'), ('nas', 'PREP+ART'), ('bancas', 'N'), ('.', 'PU')]\n",
      "Sentence 3: [('Número', 'N'), ('duplo', 'ADJ'), ('especial', 'ADJ'), (',', 'PU'), ('é', 'V'), ('inteirinho', 'ADJ'), ('dedicado', 'PCP'), ('a', 'PREP'), ('ensaios', 'N'), ('sobre', 'PREP'), ('moda', 'N'), ('.', 'PU')]\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(test_data[:3]):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lisaterumi/postagger-portuguese\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"lisaterumi/postagger-portuguese\")\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Supress output\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "teste = \"A cidade mais linda de Minas Gerais é Belo Horizonte\".split(sep=' ')\n",
    "inputs = tokenizer(teste, return_tensors=\"pt\", is_split_into_words=True, padding=True, truncation=True)\n",
    "\n",
    "# Obter os índices das palavras originais correspondentes a cada token\n",
    "word_ids = inputs.word_ids(batch_index=0)  # Adicione o batch_index para evitar erros de dimensão\n",
    "\n",
    "# Move the inputs to the GPU\n",
    "if device.type == \"cuda\":\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: [CLS], Palavra Original: None\n",
      "Token: A, Palavra Original: A\n",
      "Token: cidade, Palavra Original: cidade\n",
      "Token: mais, Palavra Original: mais\n",
      "Token: lin, Palavra Original: linda\n",
      "Token: ##da, Palavra Original: linda\n",
      "Token: de, Palavra Original: de\n",
      "Token: Minas, Palavra Original: Minas\n",
      "Token: Gerais, Palavra Original: Gerais\n",
      "Token: é, Palavra Original: é\n",
      "Token: Belo, Palavra Original: Belo\n",
      "Token: Horizonte, Palavra Original: Horizonte\n",
      "Token: [SEP], Palavra Original: None\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "# Mostrar os tokens e as palavras originais\n",
    "for token, word_id in zip(tokens, word_ids):\n",
    "    palavra_original = teste[word_id] if word_id is not None else None\n",
    "    print(f\"Token: {token}, Palavra Original: {palavra_original}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags preditas para palavras: [('A', 'ART'), ('cidade', 'N'), ('mais', 'ADV'), ('linda', 'ADJ'), ('de', 'PREP'), ('Minas', 'NPROP'), ('Gerais', 'NPROP'), ('é', 'V'), ('Belo', 'NPROP'), ('Horizonte', 'NPROP')]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Mapear previsões para palavras originais\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "tags = []\n",
    "current_word = None\n",
    "for token, word_id, pred in zip(tokens, word_ids, predictions[0].tolist()):\n",
    "    if word_id is None:  # Ignore special tokens\n",
    "        continue\n",
    "\n",
    "    # Associate tag only with the first token of each word. Repeated ids will be ignored\n",
    "    if word_id != current_word:\n",
    "        tags.append(model.config.id2label[pred])\n",
    "        current_word = word_id\n",
    "\n",
    "print(\"Tags preditas para palavras:\", list(zip(teste, tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POS_tagging(split_document, tokenizer, model):\n",
    "    \"\"\"\n",
    "    :param split_document: List of List of words\n",
    "    :param tokenizer: Tokenizer object\n",
    "    :param model: Model object\n",
    "\n",
    "    :return: List of tuples (word, tag)\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    return_predictions = []\n",
    "\n",
    "    for sentence in split_document:\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", is_split_into_words=True, padding=True, truncation=True)\n",
    "\n",
    "        # Get the indices of the original words corresponding to each token\n",
    "        word_ids = inputs.word_ids(batch_index=0)  # batch_index = 0 to avoid dimension errors\n",
    "\n",
    "        # Move the input to the GPU\n",
    "        if device.type == \"cuda\":\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "        tags = []\n",
    "        current_word = None\n",
    "        for token, word_id, pred in zip(tokens, word_ids, predictions[0].tolist()):\n",
    "            if word_id is None:  # Ignore special tokens\n",
    "                continue\n",
    "\n",
    "            # Associate tag only with the first token of each word. Repeated ids will be ignored\n",
    "            if word_id != current_word:\n",
    "                tags.append(model.config.id2label[pred])\n",
    "                current_word = word_id\n",
    "\n",
    "        return_predictions.append(list(zip(sentence, tags)))\n",
    "\n",
    "    return return_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [[t[0] for t in tup] for tup in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_test = list(itertools.chain(*test_data))\n",
    "unified_test_words, unified_test_golden_tags = zip(*unified_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_POS = POS_tagging(test_sentences, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, labels):\n",
    "    \"\"\"\n",
    "    Avalia o desempenho do modelo de POS Tagging com várias métricas.\n",
    "\n",
    "    :param y_true: Lista de tags verdadeiras.\n",
    "    :param y_pred: Lista de tags preditas pelo modelo.\n",
    "    :param labels: Lista de classes possíveis.\n",
    "    \"\"\"\n",
    "    # Acurácia geral\n",
    "    acuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Acurácia geral: {acuracy:.4f}\\n\")\n",
    "\n",
    "    # Precisão global (média ponderada)\n",
    "    precisao_global = precision_score(y_true, y_pred, labels=labels, average='weighted', zero_division=0)\n",
    "    print(f\"Precisão global (ponderada): {precisao_global:.4f}\\n\")\n",
    "\n",
    "    # Relatório detalhado por classe (inclui precisão, revocação e F1-Score)\n",
    "    print(\"Relatório de classificação por classe:\")\n",
    "    print(classification_report(y_true, y_pred, labels=labels, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of unified_test_golden_tags:  178373\n",
      "Size of unified_test_results_tags:  178373\n",
      "['<pad>', 'ADJ', 'ADV', 'ADV-KS', 'ART', 'CUR', 'IN', 'KC', 'KS', 'N', 'NPROP', 'NUM', 'PCP', 'PDEN', 'PREP', 'PREP+ADV', 'PREP+ART', 'PREP+PRO-KS', 'PREP+PROADJ', 'PREP+PROPESS', 'PREP+PROSUB', 'PRO-KS', 'PROADJ', 'PROPESS', 'PROSUB', 'PU', 'V']\n"
     ]
    }
   ],
   "source": [
    "observed_labels = model.config.label2id.keys()\n",
    "observed_labels = list(observed_labels)\n",
    "\n",
    "unified_test_results = list(itertools.chain(*test_POS))\n",
    "unified_test_results_tags = [t[1] for t in unified_test_results]\n",
    "\n",
    "print(\"Size of unified_test_golden_tags: \", len(unified_test_golden_tags))\n",
    "print(\"Size of unified_test_results_tags: \", len(unified_test_results_tags))\n",
    "print(observed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia geral: 0.9684\n",
      "\n",
      "Precisão global (ponderada): 0.9686\n",
      "\n",
      "Relatório de classificação por classe:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <pad>       0.00      0.00      0.00         0\n",
      "         ADJ       0.96      0.96      0.96      8554\n",
      "         ADV       0.94      0.90      0.92      5446\n",
      "      ADV-KS       0.85      0.85      0.85       230\n",
      "         ART       0.99      0.99      0.99     12580\n",
      "         CUR       0.00      0.00      0.00       296\n",
      "          IN       0.55      0.72      0.62        98\n",
      "          KC       0.98      0.98      0.98      4531\n",
      "          KS       0.94      0.92      0.93      2538\n",
      "           N       0.97      0.94      0.96     36542\n",
      "       NPROP       0.98      0.97      0.97     15936\n",
      "         NUM       0.68      0.96      0.79      2541\n",
      "         PCP       0.97      0.97      0.97      3640\n",
      "        PDEN       0.82      0.92      0.87      1092\n",
      "        PREP       0.98      0.99      0.98     16778\n",
      "    PREP+ADV       0.96      0.87      0.92        31\n",
      "    PREP+ART       0.99      0.99      0.99     10219\n",
      " PREP+PRO-KS       0.92      0.93      0.92        58\n",
      " PREP+PROADJ       1.00      0.99      1.00       309\n",
      "PREP+PROPESS       1.00      0.98      0.99       126\n",
      " PREP+PROSUB       0.90      0.88      0.89       156\n",
      "      PRO-KS       0.93      0.96      0.95      2195\n",
      "      PROADJ       0.97      0.97      0.97      3419\n",
      "     PROPESS       0.99      0.89      0.94      2876\n",
      "      PROSUB       0.93      0.90      0.92      1567\n",
      "          PU       0.98      1.00      0.99     26904\n",
      "           V       0.99      0.99      0.99     19711\n",
      "\n",
      "    accuracy                           0.97    178373\n",
      "   macro avg       0.86      0.87      0.86    178373\n",
      "weighted avg       0.97      0.97      0.97    178373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(unified_test_golden_tags, unified_test_results_tags, observed_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
